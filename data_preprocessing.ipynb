{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PedroChumpitaz/A-Multilingual-Human-Agent-Interaction-System-for-Enhanced-International-Dining-Experiences/blob/main/data_preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lifelines"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H5kP0sCmCwwT",
        "outputId": "d73665c0-c914-477f-ac9b-86976e098eda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting lifelines\n",
            "  Downloading lifelines-0.28.0-py3-none-any.whl (349 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/349.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.6/349.2 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m349.2/349.2 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from lifelines) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from lifelines) (1.11.4)\n",
            "Requirement already satisfied: pandas>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from lifelines) (2.0.3)\n",
            "Requirement already satisfied: matplotlib>=3.0 in /usr/local/lib/python3.10/dist-packages (from lifelines) (3.7.1)\n",
            "Requirement already satisfied: autograd>=1.5 in /usr/local/lib/python3.10/dist-packages (from lifelines) (1.6.2)\n",
            "Collecting autograd-gamma>=0.3 (from lifelines)\n",
            "  Downloading autograd-gamma-0.5.0.tar.gz (4.0 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting formulaic>=0.2.2 (from lifelines)\n",
            "  Downloading formulaic-1.0.1-py3-none-any.whl (94 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.2/94.2 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: future>=0.15.2 in /usr/local/lib/python3.10/dist-packages (from autograd>=1.5->lifelines) (0.18.3)\n",
            "Collecting interface-meta>=1.2.0 (from formulaic>=0.2.2->lifelines)\n",
            "  Downloading interface_meta-1.3.0-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from formulaic>=0.2.2->lifelines) (4.11.0)\n",
            "Requirement already satisfied: wrapt>=1.0 in /usr/local/lib/python3.10/dist-packages (from formulaic>=0.2.2->lifelines) (1.14.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines) (24.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.0->lifelines) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.0->lifelines) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.0->lifelines) (1.16.0)\n",
            "Building wheels for collected packages: autograd-gamma\n",
            "  Building wheel for autograd-gamma (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for autograd-gamma: filename=autograd_gamma-0.5.0-py3-none-any.whl size=4030 sha256=38f3367cf1cc2d39710f79becdf1a24c2b782dac69adc5dfb211844a93be92e5\n",
            "  Stored in directory: /root/.cache/pip/wheels/25/cc/e0/ef2969164144c899fedb22b338f6703e2b9cf46eeebf254991\n",
            "Successfully built autograd-gamma\n",
            "Installing collected packages: interface-meta, autograd-gamma, formulaic, lifelines\n",
            "Successfully installed autograd-gamma-0.5.0 formulaic-1.0.1 interface-meta-1.3.0 lifelines-0.28.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PUFmV6dYdAnz",
        "outputId": "0729b2da-e172-4ee6-8704-153ddb24ff77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from lifelines import KaplanMeierFitter\n",
        "\n",
        "# Funciones para cargar datos de cada módulo\n",
        "def mean_survival_time_km(group):\n",
        "    T = group['TVIDA']\n",
        "    E = np.ones_like(T)  # Suponemos que todos los eventos están censurados\n",
        "\n",
        "    kmf = KaplanMeierFitter()\n",
        "    kmf.fit(T, event_observed=E, label='Kaplan-Meier')\n",
        "\n",
        "    kmf_times = kmf.survival_function_.index\n",
        "    kmf_probabilities = kmf.survival_function_['Kaplan-Meier']\n",
        "    mean_survival_time = np.sum(np.diff(kmf_times) * kmf_probabilities.iloc[:-1])\n",
        "\n",
        "    return mean_survival_time\n",
        "\n",
        "def cargar_datos_mod_18(year):\n",
        "    ruta = f'/content/drive/MyDrive/Survival-modeling-2024/data/mod-18/Enaho01-{year}.csv'\n",
        "    df = pd.read_csv(ruta, encoding='latin1')\n",
        "    df = df[df['P612N'] == 2]\n",
        "    variables_cualitativas = ['AÑO', 'MES', 'CONGLOME', 'VIVIENDA', 'HOGAR', 'UBIGEO', 'DOMINIO', 'ESTRATO', 'P612N', 'P612', 'P612B', 'P612C', 'P612C1', 'FACTOR07', 'NCONGLOME']\n",
        "    variables_cuantitativas = ['P612A', 'P612G', 'P612H', 'D612G', 'D612H', 'I612G', 'I612H', 'TICUEST01']\n",
        "    variables_cualitativas = [col for col in variables_cualitativas if col in df.columns]\n",
        "    variables_cuantitativas = [col for col in variables_cuantitativas if col in df.columns]\n",
        "    df = df[variables_cualitativas + variables_cuantitativas]\n",
        "    for col in variables_cuantitativas:\n",
        "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "    df['AÑO'] = pd.to_numeric(df['AÑO'], errors='coerce')\n",
        "    df['P612C'] = pd.to_numeric(df['P612C'], errors='coerce')\n",
        "    valores_a_eliminar = [99, 999, 9999, 99999, 999999, 999999.99, 9]\n",
        "    for valor in valores_a_eliminar:\n",
        "        df = df.replace(valor, np.nan)\n",
        "    df = df.dropna(subset=['P612C'])\n",
        "\n",
        "    df['TVIDA'] = df['AÑO'] - df['P612C']\n",
        "    df = df[df['TVIDA'] > 0]\n",
        "\n",
        "    grouped = df.groupby('UBIGEO')\n",
        "\n",
        "    resumen_cualitativo = grouped[variables_cualitativas].agg(moda)\n",
        "    resumen_cuantitativo = grouped[variables_cuantitativas].agg(mediana)\n",
        "\n",
        "    # Calcular el tiempo medio de supervivencia para cada grupo y agregarlo al resumen\n",
        "    mean_survival_times = grouped.apply(mean_survival_time_km)\n",
        "    mean_survival_times.name = 'mean_survival_time_km'\n",
        "\n",
        "    resumen = pd.concat([resumen_cualitativo, resumen_cuantitativo, mean_survival_times], axis=1)\n",
        "    columnas_seleccionadas = ['AÑO', 'P612A', 'P612B', 'P612C', 'FACTOR07', 'P612G', 'P612H', 'D612G', 'D612H', 'I612G', 'I612H', 'mean_survival_time_km']\n",
        "    resumen = resumen[columnas_seleccionadas]\n",
        "    resumen = resumen.reset_index()\n",
        "    resumen = resumen.rename(columns={'FACTOR07': 'FACTOR07_MOD18'})\n",
        "    return resumen\n",
        "\n",
        "def cargar_datos_mod_32(year):\n",
        "    ruta_sumaria = f'/content/drive/MyDrive/Survival-modeling-2024/data/mod-32/Sumaria-{year}.csv'\n",
        "    df = pd.read_csv(ruta_sumaria, encoding='latin1')\n",
        "    col_m32 = ['AÑO', 'UBIGEO', 'INGMO2HD', 'FACTOR07', 'SG42', 'SG42D']\n",
        "    df = df[col_m32]\n",
        "    variables_cualitativas = ['AÑO']\n",
        "    variables_cuantitativas = ['INGMO2HD', 'FACTOR07']\n",
        "    variables_excluyentes = ['SG42', 'SG42D']\n",
        "    for col in variables_cuantitativas + variables_excluyentes:\n",
        "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "    df['AÑO'] = pd.to_numeric(df['AÑO'], errors='coerce')\n",
        "    grouped = df.groupby('UBIGEO')\n",
        "    resumen_cualitativo = grouped[variables_cualitativas].agg(moda)\n",
        "    resumen_cuantitativo = grouped[variables_cuantitativas].agg(mediana)\n",
        "    resumen_excluyente = grouped[variables_excluyentes].agg(mediana_excluyendo_ceros)\n",
        "    resumen = pd.concat([resumen_cualitativo, resumen_cuantitativo, resumen_excluyente], axis=1)\n",
        "    resumen = resumen.reset_index()\n",
        "    resumen = resumen.rename(columns={'FACTOR07': 'FACTOR07_SUMARIA'})\n",
        "    return resumen\n",
        "\n",
        "def cargar_datos_mod_01(year):\n",
        "    ruta_sumaria = f'/content/drive/MyDrive/Survival-modeling-2024/data/mod-1/Enaho01-{year}.csv'\n",
        "    df = pd.read_csv(ruta_sumaria, encoding='latin1')\n",
        "    variables_cualitativas = ['AÑO', 'P101', 'P102', 'P103', 'P103A', 'P1143', 'P1144']\n",
        "    variables_cuantitativas = ['P104']\n",
        "    for col in variables_cuantitativas:\n",
        "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "    df['AÑO'] = pd.to_numeric(df['AÑO'], errors='coerce')\n",
        "    grouped = df.groupby('UBIGEO')\n",
        "    resumen_cualitativo = grouped[variables_cualitativas].agg(moda)\n",
        "    resumen_cuantitativo = grouped[variables_cuantitativas].agg(mediana)\n",
        "    resumen = pd.concat([resumen_cualitativo, resumen_cuantitativo], axis=1)\n",
        "    resumen = resumen.reset_index()\n",
        "    return resumen\n",
        "\n",
        "def cargar_datos_mod_05(year):\n",
        "    ruta_sumaria = f'/content/drive/MyDrive/Survival-modeling-2024/data/mod-5/Enaho01-{year}.csv'\n",
        "    df = pd.read_csv(ruta_sumaria, encoding='latin1')\n",
        "    variables_cualitativas = ['AÑO', 'P510']\n",
        "    df['AÑO'] = pd.to_numeric(df['AÑO'], errors='coerce')\n",
        "    df['P510'] = pd.to_numeric(df['P510'], errors='coerce')\n",
        "    grouped = df.groupby('UBIGEO')\n",
        "    resumen_cualitativo = grouped[variables_cualitativas].agg(moda_excluyendo_ceros)\n",
        "    resumen_cualitativo = resumen_cualitativo.reset_index()\n",
        "    return resumen_cualitativo\n",
        "\n",
        "def cargar_datos_mod_03(year):\n",
        "    ruta_sumaria = f'/content/drive/MyDrive/Survival-modeling-2024/data/mod-3/Enaho01-{year}.csv'\n",
        "    df = pd.read_csv(ruta_sumaria, encoding='latin1')\n",
        "    variables_cualitativas = ['AÑO', 'P301A']\n",
        "    df['AÑO'] = pd.to_numeric(df['AÑO'], errors='coerce')\n",
        "    df['P301A'] = pd.to_numeric(df['P301A'], errors='coerce')\n",
        "    grouped = df.groupby('UBIGEO')\n",
        "    resumen_cualitativo = grouped[variables_cualitativas].agg(moda_excluyendo_ceros)\n",
        "    resumen_cualitativo = resumen_cualitativo.reset_index()\n",
        "    return resumen_cualitativo\n",
        "\n",
        "# Definir funciones de agregación\n",
        "def moda(series):\n",
        "    series = series.dropna()\n",
        "    return series.mode().iloc[0] if not series.mode().empty else np.nan\n",
        "\n",
        "def mediana(series):\n",
        "    series = series.dropna()\n",
        "    return series.median() if not series.empty else np.nan\n",
        "\n",
        "def mediana_excluyendo_ceros(series):\n",
        "    series = series.replace(0, np.nan).dropna()\n",
        "    return series.median() if not series.empty else np.nan\n",
        "\n",
        "def moda_excluyendo_ceros(series):\n",
        "    series = series.replace(0, np.nan).dropna()\n",
        "    return series.mode().iloc[0] if not series.mode().empty else np.nan\n",
        "\n",
        "# Procesar los datos de cada módulo para los años 2008 a 2023 y concatenar los resultados\n",
        "all_years_data = []\n",
        "\n",
        "for year in range(2016, 2023 + 1):\n",
        "    resumen_mod18 = pd.DataFrame()\n",
        "    resumen_mod32 = pd.DataFrame()\n",
        "    resumen_mod01 = pd.DataFrame()\n",
        "    resumen_mod05 = pd.DataFrame()\n",
        "    resumen_mod03 = pd.DataFrame()\n",
        "\n",
        "    resumen_mod18 = cargar_datos_mod_18(year)\n",
        "    resumen_mod32 = cargar_datos_mod_32(year)\n",
        "    resumen_mod01 = cargar_datos_mod_01(year)\n",
        "    resumen_mod05 = cargar_datos_mod_05(year)\n",
        "    resumen_mod03 = cargar_datos_mod_03(year)\n",
        "\n",
        "    # Fusionar los DataFrames usando 'UBIGEO' y 'AÑO'\n",
        "    df_combinado = resumen_mod18.merge(resumen_mod32, on=['UBIGEO', 'AÑO'], how='inner')\n",
        "    df_combinado = df_combinado.merge(resumen_mod01, on=['UBIGEO', 'AÑO'], how='inner')\n",
        "    df_combinado = df_combinado.merge(resumen_mod05, on=['UBIGEO', 'AÑO'], how='inner')\n",
        "    df_combinado = df_combinado.merge(resumen_mod03, on=['UBIGEO', 'AÑO'], how='inner')\n",
        "\n",
        "    all_years_data.append(df_combinado)\n",
        "\n",
        "# Concatenar todos los resultados en un único DataFrame\n",
        "df_final = pd.concat(all_years_data, ignore_index=True)\n",
        "\n",
        "# Cargar DataFrame de ubigeo desde el archivo\n",
        "ruta_ubigeo = '/content/drive/MyDrive/Survival-modeling-2024/data/ubigeo_lima.csv'\n",
        "ubigeo = pd.read_csv(ruta_ubigeo, encoding='latin1')\n",
        "\n",
        "# Filtrar los datos para Lima usando el DataFrame de ubigeo\n",
        "df_lima = df_final[df_final['UBIGEO'].isin(ubigeo['UBIGEO'])]\n",
        "\n",
        "# Agregar columnas de \"DISTRITO\", \"PROVINCIA\", \"PERFIL ZONAL\" del DataFrame ubigeo\n",
        "df_lima = df_lima.merge(ubigeo[['UBIGEO', 'DISTRITO', 'PROVINCIA', 'PERFIL ZONAL']], on='UBIGEO', how='left')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dTcYdgu1pHb0",
        "outputId": "a4d1ec81-ea9f-4e80-bb6d-2b4aeb06d156"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-86c6f9ff2f02>:93: DtypeWarning: Columns (212,217,222,230,235,240,245,250,255,262,265,268,271,274,277,280,283,287,289,291,293,295,297,299,302,303,304,305,306,310,311,397,398,399,400,517,518,519,520,521,522,523,524,525,526,597,600,605,768,770,771,772,773,774,775,776,777,778,779,780,781,782,783,784,785,786) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(ruta_sumaria, encoding='latin1')\n",
            "<ipython-input-5-86c6f9ff2f02>:104: DtypeWarning: Columns (13,14,27,33,44,213,228,295) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(ruta_sumaria, encoding='latin1')\n",
            "<ipython-input-5-86c6f9ff2f02>:21: DtypeWarning: Columns (17) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(ruta, encoding='latin1')\n",
            "<ipython-input-5-86c6f9ff2f02>:93: DtypeWarning: Columns (20,21,22,23,24,25,26,27,28,29,30,31,32,33,201,202,203,208,212,217,222,230,235,240,245,250,255,262,265,268,271,274,277,280,283,287,289,291,293,295,297,299,300,301,302,303,304,305,306,310,311,313,314,315,316,317,403,404,405,406,407,419,421,434,436,449,451,464,466,479,481,523,524,525,526,527,528,529,530,531,532,534,544,554,564,574,603,609,614,658,677,679,692,702,704,717,729,742,744,757,759,772,774,775,777,778,779,780,781,782,783,784,785,786,787,788,789,790,791,792,793) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(ruta_sumaria, encoding='latin1')\n",
            "<ipython-input-5-86c6f9ff2f02>:104: DtypeWarning: Columns (13,14,27,33,44,213,228,316) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(ruta_sumaria, encoding='latin1')\n",
            "<ipython-input-5-86c6f9ff2f02>:93: DtypeWarning: Columns (212,217,222,230,235,240,245,250,255,260,265,270,275,280,287,290,293,296,299,302,305,308,312,314,316,318,320,322,324,327,328,329,330,331,335,336,424,425,426,427,824,825,826,827,828,829,830,831,832,833,904,1318,1323,1326,1328,1329,1330,1331,1332,1333,1334,1335,1336,1337,1338,1339,1340,1341,1342,1343,1344) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(ruta_sumaria, encoding='latin1')\n",
            "<ipython-input-5-86c6f9ff2f02>:104: DtypeWarning: Columns (13,14,27,33,46,215,230) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(ruta_sumaria, encoding='latin1')\n",
            "<ipython-input-5-86c6f9ff2f02>:78: DtypeWarning: Columns (210) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(ruta_sumaria, encoding='latin1')\n",
            "<ipython-input-5-86c6f9ff2f02>:93: DtypeWarning: Columns (212,217,222,230,235,240,245,250,255,260,265,270,275,280,287,290,293,296,299,302,305,308,312,314,316,318,320,322,324,327,328,329,330,331,335,336,424,425,426,427,874,875,876,877,878,879,880,881,882,883,954,957,962,1335,1336,1337,1338,1339,1340,1341,1342,1343,1344,1345,1346,1347,1348,1349,1350,1351) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(ruta_sumaria, encoding='latin1')\n",
            "<ipython-input-5-86c6f9ff2f02>:104: DtypeWarning: Columns (13,14,27,33,46,215,230) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(ruta_sumaria, encoding='latin1')\n",
            "<ipython-input-5-86c6f9ff2f02>:21: DtypeWarning: Columns (24) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(ruta, encoding='latin1')\n",
            "<ipython-input-5-86c6f9ff2f02>:78: DtypeWarning: Columns (322) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(ruta_sumaria, encoding='latin1')\n",
            "<ipython-input-5-86c6f9ff2f02>:93: DtypeWarning: Columns (229,234,239,247,252,257,262,267,272,277,282,287,292,297,302,307,311,316,320,325,329,334,341,344,347,350,353,356,359,362,365,366,367,369,371,373,375,377,379,381,382,383,384,385,386,387,391,484,485,486,487,934,935,936,937,938,939,940,941,942,943,1014,1017,1022,1408) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(ruta_sumaria, encoding='latin1')\n",
            "<ipython-input-5-86c6f9ff2f02>:104: DtypeWarning: Columns (12,13,26,32,59,130,296,311,559,560,565) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(ruta_sumaria, encoding='latin1')\n",
            "<ipython-input-5-86c6f9ff2f02>:21: DtypeWarning: Columns (23) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(ruta, encoding='latin1')\n",
            "<ipython-input-5-86c6f9ff2f02>:78: DtypeWarning: Columns (323) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(ruta_sumaria, encoding='latin1')\n",
            "<ipython-input-5-86c6f9ff2f02>:93: DtypeWarning: Columns (229,234,239,247,252,257,262,267,272,277,282,287,292,297,302,307,312,317,322,327,332,337,342,347,354,358,362,366,370,431,434,437,440,443,446,449,452,457,459,461,463,465,467,469,473,474,475,476,477,481,573,574,575,576,1023,1024,1025,1026,1027,1028,1029,1030,1031,1032,1103,1106,1111,1456) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(ruta_sumaria, encoding='latin1')\n",
            "<ipython-input-5-86c6f9ff2f02>:104: DtypeWarning: Columns (12,13,26,32,59,346,510) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(ruta_sumaria, encoding='latin1')\n",
            "<ipython-input-5-86c6f9ff2f02>:93: DtypeWarning: Columns (226,231,236,244,249,254,259,264,269,274,279,284,289,294,299,304,309,314,319,324,329,334,339,344,356,368,371,374,377,380,383,386,389,393,395,397,399,401,403,405,407,409,413,414,415,416,417,421,512,513,514,515,962,963,964,965,966,967,968,969,970,971,1042,1045,1050) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(ruta_sumaria, encoding='latin1')\n",
            "<ipython-input-5-86c6f9ff2f02>:104: DtypeWarning: Columns (12,13,26,32,60) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(ruta_sumaria, encoding='latin1')\n",
            "<ipython-input-5-86c6f9ff2f02>:93: DtypeWarning: Columns (218,223,228,231,234,235,236,241,246,251,256,261,266,271,276,281,286,291,296,301,306,311,316,321,326,331,338,341,344,347,350,353,356,359,363,365,367,369,371,373,375,377,379,381,385,386,387,388,389,393,485,486,487,488,935,936,937,938,939,940,941,942,943,944,1015,1018,1023) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(ruta_sumaria, encoding='latin1')\n",
            "<ipython-input-5-86c6f9ff2f02>:104: DtypeWarning: Columns (26,32,60) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(ruta_sumaria, encoding='latin1')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "2fP2VksMphfC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Especifica la ruta donde quieres guardar el archivo\n",
        "file_path = '/content/drive/MyDrive/Survival-modeling-2024/df_lima.csv'\n",
        "\n",
        "# Guarda el DataFrame como un archivo CSV\n",
        "df_lima.to_csv(file_path, index=False)"
      ],
      "metadata": {
        "id": "8nOeHNW2lIAm"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}